在当前开源盛行，各种分布式存储系统层出不穷，以leveldb为代表的LSM系列kv存储，redis为代表的内存存储系统，还有半结构化的mongodb，这些系统的诞生为当下十分火热的大数据，云计算提供了重要的技术基础。每一款存储系统的出现，都有它适用的场景，例如leveldb在传统机械硬盘的环境下能提供非常高效的读写效率，在提升效率的同时，有效降低了存储成本。redis作为一款内存kv存储系统，高效是它的根本，同时它提供了丰富的数据结构，为数据的使用提供了便捷，然而在数据持久化方面是它所欠缺的。

##### 总体架构

和leveldb一样，skar也是基于skiplist一个key/value存储系统，与之不同的是leveldb是单个kv，后面的kv会覆盖之前kv的value值，因此，系统中永远只有一个有效的value值。然而对与实际中的一些场景，一个key往往对应了一个set，如一个班级，一个国家等，kv存储往往需要再做一层索引转换，在这样的情况下，一个key，mutli_values的存储系统往往可以很好的解决问题，即一个key映射了一个set，我把它称为k-s存储。skar存储系统的总体架构如下图所示：

![scar总体架构](https://github.com/alxbean/alxbean.github.io/blob/master/assets/skar/skar总体架构.png?raw=true)

scar的结构非常简单，主要分成了3层：

1. 客户端

用于提供数据操作接口，增删改查数据等

2. 内存存储

内存存储主要是内存中的skiplist结构，用于存储数据的索引，及缓存，而且每个结点是范围结点，同时采用了WAL的日志结构来保证数据的可靠性

3. 持久化存储层

持久化存储层即底层文存储层，通过linux posix文件系统作为底层存储的基础

##### 数据流

skar数据流非常简单，没有过长的io路径，从而保证了数据读写的高效性。在内存存储层，采用了LSM的存储结构，解决了传统机械硬盘随机写带来的性能损耗，从而提升了写数据的效率。

1. 数据写

   ![写数据流](https://github.com/alxbean/alxbean.github.io/blob/master/assets/skar/写数据流.png?raw=true)

   写数据流首先在客户端发起调用，写入数据，然后在服务端首先记录到log日志中，记录完成后，在将写入文件系统，并更新内存中的跳表结构，记录其在文件中的索引位置

2. 数据读

![读数据流](https://github.com/alxbean/alxbean.github.io/blob/master/assets/skar/读数据流.png?raw=true)

用户发起读数据流后，首先根据key查询skiplist中相应的索引结点，并查询到该结点在文件中的位置，再到文件系统中查询该文件的数据，并返回给客户端完成查询。

##### 关于skiplist

skiplist即跳表，它是一种随机化的链表结构，查找效率能够达到Olog(n)，基本上是一颗AVL树的查找效率，然而skiplist的实现上却简单很多。一个简单的skiplist结构如下所示：

![简单3层跳表](https://github.com/alxbean/alxbean.github.io/blob/master/assets/skar/3层跳表.png?raw=true)

如上图所示，查找结点17，可以直接在第三层跳过5，8结点，直接到10结点，然后下沉一个结点便可以查到17结点，从而大大的提高了查找效率。

##### 基于范围结点的skiplist

跳表能够达到Olog(n)的查找效率，但是它的key是唯一结点，在skar的底层设计中，设计的是一个结点对应了一个底层文件，那么将极大的浪费底层文件系统的inode，创建出大量的小文件，在key到百万级别，linux的文件系统将难以支撑，为此，将skiplist进行扩展，使的每个结点对应一个key的范围，该结点范围内的value值都存放在同一个底层文件中，当文件超过一点阈值时，对该结点进行分裂，将原文件重新分裂成2个新的底层文件，当两个相邻结点文件的小于一定的阈值时，将这两个结点重新合并成一个结点。基于范围结点的skiplist结构的实现使的，linux底层文件系统足以支撑数千万上亿级别的的kv结点，大大提升了skar的可用性。

![范围跳表](https://github.com/alxbean/alxbean.github.io/blob/master/assets/skar/范围跳表.png?raw=true)

范围跳表中的每个结点是一个三元组结构<左边界，右边界，文件块索引>，通过该三元组结构可以表示出一个范围结点，其中左边界，表示大于并且等于该值，右边界表示小于该值，即[左边界，右边界)，文件块索引表示该结点所对应的文件块，方便数据的查询操作。

##### 基于skiplist的持久化kv存储

在skar中的每次io的数据最终需要落盘，然而内存中的skiplist结构并为做持久化存储，不过可以通过在文件中的数据重新恢复。因此，文件中的存储结构的设计至关重要。为了方便skiplist结构的恢复，skar文件主要分为3块数据，在文件头存储了该文件的类型，文件块个数，以及文件当前的大小。第二部分存储了文件块的索引结构，按顺序排序，不再额外存储索引数据，主要包括了索引，数据块偏移，数据大小。通过数据块偏移，和数据的长度可以定位到该文件中的唯一数据块。第三部分即数据部分。

* 文件头

```
+-------------+-------------+-------------+
| count       | offset      | version     |
+-------------+-------------+-------------+
```

* 索引块

```
+-------------+-------------+-------------+
| block_type  | block_used  | block_offset|
+-------------+-------------+-------------+
```



* 数据块

```
+-------------+-------------+-------------+-------------+-------------+
| COMM        | key_len     | key         | value_len   | value       |
+-------------+-------------+-------------+-------------+-------------+
+-------------+-------------+-------------+-------------+-------------+-------------+
| CPAT        | key_len     | key         | value_count | value_len   | value       |
+-------------+-------------+-------------+-------------+-------------+-------------+
+-------------+-------------+-------------+-------------------+--------------------+
| DEEP_CPAT   | key_len     | key         | head_compact_idx  |  tail_compact_idx  |
+-------------+-------------+-------------+-------------+-----+--------------------+
```

数据块有分为3种类型：

```c
typedef enum{
    COMM_SLICE = 0,
    CPAT_SLICE = 1,
    DEEP_CPAT_SLICE = 2
}
```

* COMM_SLICE表示普通数据块，包含了一个key，一个value
* CAPT_SLICE表示一个key，多个value
* DEEP_CPAT_SLICE表示包括了多个CPAT_SLICE的链表

 



